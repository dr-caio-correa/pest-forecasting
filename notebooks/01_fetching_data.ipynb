{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b361dd",
   "metadata": {},
   "source": [
    "### Setup and Imports\n",
    "\n",
    "This notebook downloads hourly Environment Canada weather data for all Ontario stations for the year 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37910f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from env_canada import ECHistoricalRange\n",
    "from io import StringIO\n",
    "import time\n",
    "import nest_asyncio\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3dab72",
   "metadata": {},
   "source": [
    "### Load Ontario weather station metadata\n",
    "\n",
    "A reference table containing station names and ids was previously created by selecting only stations relevant to the agricultural sector in Ontario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc41a5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 [42967, 52900, 10220, 26799, 42183, 44183, 55238, 53378, 47567, 7868]\n"
     ]
    }
   ],
   "source": [
    "station_ids = pd.read_csv(\"../data/metadata/weather_stations.csv\")\n",
    "station_ids = station_ids[\"station_id\"].astype(int).tolist()\n",
    "print(len(station_ids), station_ids[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a5d73d",
   "metadata": {},
   "source": [
    "### Define helper function for downloading hourly station data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e88cef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_station_hourly(station_id, start_date, end_date):\n",
    "    try:\n",
    "        ec = ECHistoricalRange(\n",
    "            station_id=station_id,\n",
    "            timeframe=\"hourly\",\n",
    "            daterange=(start_date, end_date),\n",
    "        )\n",
    "        ec.get_data()\n",
    "\n",
    "        df = pd.read_csv(StringIO(ec.csv), sep=\";\")\n",
    "        df.columns = df.columns.str.strip()\n",
    "        df[\"station_id\"] = station_id\n",
    "        df[\"Date/Time (LST)\"] = pd.to_datetime(df[\"Date/Time (LST)\"], errors=\"coerce\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Station {station_id} failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49468e68",
   "metadata": {},
   "source": [
    "### Initialize environment and define update window  \n",
    "Apply async support, define the local weather CSV path, set the requested date range (capped to today), and load existing weather data if the file already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9242d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "csv_path = \"../data/raw/hourly_weather_data.csv\"\n",
    "\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date   = datetime(2025, 12, 31)\n",
    "end_date   = min(end_date, datetime.now())\n",
    "\n",
    "# load existing CSV (or start empty)\n",
    "if os.path.exists(csv_path):\n",
    "    df_weather = pd.read_csv(csv_path)\n",
    "    df_weather[\"Date/Time (LST)\"] = pd.to_datetime(df_weather[\"Date/Time (LST)\"], errors=\"coerce\")\n",
    "else:\n",
    "    df_weather = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f8ddb",
   "metadata": {},
   "source": [
    "### Identify missing dates per station and download only required data  \n",
    "For each weather station, compare the dates already present in the existing dataset against the requested date range, identify any missing days, and download only the necessary hourly data to fill those gaps while avoiding redundant requests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1493c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ 42967: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 52900: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 10220: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 26799: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 42183: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 44183: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 55238: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 53378: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 47567: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 7868: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 27674: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 55360: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 53603: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 55258: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 52118: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 7870: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 27528: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 48869: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 27865: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 49489: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 47687: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 27604: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 41983: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 46507: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 54240: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 54858: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 7747: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 48788: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 48372: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 10903: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 55299: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 49908: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 27529: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 30266: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 52604: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 54260: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 30435: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 27534: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 51137: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 47307: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 54958: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 52985: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 47267: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 55367: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 48569: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 10911: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 51958: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 43104: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 50093: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 10999: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 53138: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 41738: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 7844: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 48368: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 7633: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 4656: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 52318: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 54604: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 48649: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 30578: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 49568: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 32128: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 10197: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 52878: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 49068: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 48952: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 55365: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 27533: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 7925: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 7790: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 49848: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 30455: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 32473: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 10899: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 44323: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 50092: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 51138: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 53000: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 50840: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 49508: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 54606: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 49389: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 50132: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 30682: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 50460: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 47547: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 45607: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 31688: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 48549: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 51459: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 5126: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 4057: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 50637: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 31367: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 52998: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 4061: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 44283: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 53139: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n",
      "⬇️ 54738: downloading 2023-01-01 to 2024-12-31 (731 missing days)\n"
     ]
    }
   ],
   "source": [
    "new_frames = []\n",
    "3\n",
    "0\n",
    "\n",
    "for sid in station_ids:\n",
    "    # what dates we already have for this station\n",
    "    if not df_weather.empty:\n",
    "        have_dates = (\n",
    "            df_weather.loc[df_weather[\"station_id\"] == sid, \"Date/Time (LST)\"]\n",
    "            .dropna()\n",
    "            .dt.date\n",
    "            .unique()\n",
    "        )\n",
    "        have_dates = set(have_dates)\n",
    "    else:\n",
    "        have_dates = set()\n",
    "\n",
    "    want_dates = set(pd.date_range(start_date, end_date, freq=\"D\").date)\n",
    "    missing_dates = sorted(want_dates - have_dates)\n",
    "\n",
    "    if not missing_dates:\n",
    "        print(f\"✅ {sid}: up to date\")\n",
    "        continue\n",
    "\n",
    "    # download one continuous range: from first missing day to last missing day\n",
    "    dl_start = datetime.combine(missing_dates[0], datetime.min.time())\n",
    "    dl_end   = datetime.combine(missing_dates[-1], datetime.max.time())\n",
    "\n",
    "    print(f\"⬇️ {sid}: downloading {missing_dates[0]} to {missing_dates[-1]} ({len(missing_dates)} missing days)\")\n",
    "    df_sid = fetch_station_hourly(sid, dl_start, dl_end)\n",
    "    if df_sid is not None and not df_sid.empty:\n",
    "        new_frames.append(df_sid)\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc1c0f",
   "metadata": {},
   "source": [
    "### Append new data, remove duplicates, and persist updated dataset  \n",
    "Combine newly downloaded weather records with the existing dataset, enforce uniqueness at the station–hour level, and save the updated weather file back to disk only if new data was retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f80b9fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: ../data/raw/hourly_weather_data.csv | shape: (2601819, 32)\n"
     ]
    }
   ],
   "source": [
    "# append + dedupe + save\n",
    "if new_frames:\n",
    "    df_new = pd.concat(new_frames, ignore_index=True)\n",
    "    df_weather = pd.concat([df_weather, df_new], ignore_index=True)\n",
    "\n",
    "    df_weather[\"Date/Time (LST)\"] = pd.to_datetime(df_weather[\"Date/Time (LST)\"], errors=\"coerce\")\n",
    "    df_weather = df_weather.drop_duplicates(subset=[\"station_id\", \"Date/Time (LST)\"]).reset_index(drop=True)\n",
    "\n",
    "    df_weather.to_csv(csv_path, index=False)\n",
    "    print(\"✅ Saved:\", csv_path, \"| shape:\", df_weather.shape)\n",
    "else:\n",
    "    print(\"No new data needed. CSV unchanged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "93daa0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time (LST)</th>\n",
       "      <th>Longitude (x)</th>\n",
       "      <th>Latitude (y)</th>\n",
       "      <th>Station Name</th>\n",
       "      <th>Climate ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time (LST)</th>\n",
       "      <th>Flag</th>\n",
       "      <th>...</th>\n",
       "      <th>Visibility (km)</th>\n",
       "      <th>Visibility Flag</th>\n",
       "      <th>Stn Press (kPa)</th>\n",
       "      <th>Stn Press Flag</th>\n",
       "      <th>Hmdx</th>\n",
       "      <th>Hmdx Flag</th>\n",
       "      <th>Wind Chill</th>\n",
       "      <th>Wind Chill Flag</th>\n",
       "      <th>Weather</th>\n",
       "      <th>station_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8736</th>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>-78.27</td>\n",
       "      <td>45.53</td>\n",
       "      <td>ALGONQUIN PARK EAST GATE</td>\n",
       "      <td>6080192</td>\n",
       "      <td>2025</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17473</th>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>-88.91</td>\n",
       "      <td>50.29</td>\n",
       "      <td>ARMSTRONG A</td>\n",
       "      <td>6040327</td>\n",
       "      <td>2025</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26210</th>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>-91.63</td>\n",
       "      <td>48.76</td>\n",
       "      <td>ATIKOKAN (AUT)</td>\n",
       "      <td>6020LPQ</td>\n",
       "      <td>2025</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34947</th>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>-77.88</td>\n",
       "      <td>45.07</td>\n",
       "      <td>BANCROFT AUTO</td>\n",
       "      <td>616I001</td>\n",
       "      <td>2025</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43684</th>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>-79.55</td>\n",
       "      <td>44.48</td>\n",
       "      <td>BARRIE-ORO</td>\n",
       "      <td>6117700</td>\n",
       "      <td>2025</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date/Time (LST)  Longitude (x)  Latitude (y)              Station Name  \\\n",
       "8736       2025-12-31         -78.27         45.53  ALGONQUIN PARK EAST GATE   \n",
       "17473      2025-12-31         -88.91         50.29               ARMSTRONG A   \n",
       "26210      2025-12-31         -91.63         48.76            ATIKOKAN (AUT)   \n",
       "34947      2025-12-31         -77.88         45.07             BANCROFT AUTO   \n",
       "43684      2025-12-31         -79.55         44.48                BARRIE-ORO   \n",
       "\n",
       "      Climate ID  Year  Month  Day Time (LST) Flag  ...  Visibility (km)  \\\n",
       "8736     6080192  2025     12   31      00:00  NaN  ...              NaN   \n",
       "17473    6040327  2025     12   31      00:00  NaN  ...             16.1   \n",
       "26210    6020LPQ  2025     12   31      00:00  NaN  ...              NaN   \n",
       "34947    616I001  2025     12   31      00:00  NaN  ...              NaN   \n",
       "43684    6117700  2025     12   31      00:00  NaN  ...              NaN   \n",
       "\n",
       "      Visibility Flag  Stn Press (kPa) Stn Press Flag  Hmdx Hmdx Flag  \\\n",
       "8736              NaN            95.28            NaN   NaN       NaN   \n",
       "17473             NaN            97.16            NaN   NaN       NaN   \n",
       "26210             NaN            96.48            NaN   NaN       NaN   \n",
       "34947             NaN            96.20            NaN   NaN       NaN   \n",
       "43684             NaN            96.95            NaN   NaN       NaN   \n",
       "\n",
       "       Wind Chill Wind Chill Flag  Weather station_id  \n",
       "8736        -21.0             NaN      NaN      42967  \n",
       "17473       -27.0             NaN      NaN      52900  \n",
       "26210       -17.0             NaN      NaN      10220  \n",
       "34947       -20.0             NaN      NaN      26799  \n",
       "43684       -15.0             NaN      NaN      42183  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.sort_values(\n",
    "    by=[\"Date/Time (LST)\", \"Station Name\"],\n",
    "    ascending=[False, True]\n",
    ").head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
